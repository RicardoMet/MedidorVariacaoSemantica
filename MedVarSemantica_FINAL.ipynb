{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Dependências e setup\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from datetime import datetime\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "!pip install -q spacy openpyxl\n",
        "!python -m spacy download pt_core_news_lg\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_lg\")"
      ],
      "metadata": {
        "id": "a7FRY46b5t9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Montar Google Drive\n",
        "# ======================\n",
        "drive.mount('/content/drive/')\n",
        "file = \"/content/drive/MyDrive/Constructions_concordances/EXEMPLO.xml\" #<------ Substituir nome do ficheiro pelo do ficheiro a analisar"
      ],
      "metadata": {
        "id": "IsGkHD_w5u3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Escolher a construção\n",
        "# ======================\n",
        "tipo_construcao = \"svo\"  # 'svo', 'n_adj', 'adj_n'"
      ],
      "metadata": {
        "id": "AD-xXWIC5u1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# Funções de pré-processamento\n",
        "# =============================\n",
        "def limpar_kwic(texto_kwic):\n",
        "    return re.sub(r\"/[a-z]+\", \"\", texto_kwic)\n",
        "\n",
        "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "    xml = f.read()\n",
        "\n",
        "soup = BeautifulSoup(xml, \"xml\")\n",
        "kwics = soup.find_all(\"kwic\")\n",
        "kwic_pairs = [(limpar_kwic(k.text.strip()), k.text.strip()) for k in kwics]\n",
        "\n",
        "frases_limpas = [pair[0] for pair in kwic_pairs]\n",
        "frases_originais = [pair[1] for pair in kwic_pairs]"
      ],
      "metadata": {
        "id": "oNRCi0lJ5uuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================\n",
        "# Funções de extração sintática\n",
        "# ===================================\n",
        "def extrair_svo(frase):\n",
        "    doc = nlp(frase)\n",
        "    sujeito = verbo = objeto = None\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            verbo = token.lemma_\n",
        "        elif token.dep_ == \"nsubj\":\n",
        "            sujeito = token.text\n",
        "        elif token.dep_ in {\"obj\", \"dobj\", \"obl\", \"attr\"}:\n",
        "            objeto = token.lemma_\n",
        "    if verbo and (sujeito or objeto):\n",
        "        return {\n",
        "            \"frase_limpa\": frase,\n",
        "            \"sujeito\": sujeito if sujeito else \"\",\n",
        "            \"verbo\": verbo,\n",
        "            \"objeto\": objeto if objeto else \"\"\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def extrair_n_adj(frase):\n",
        "    doc = nlp(frase)\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"ADJ\" and token.head.pos_ == \"NOUN\":\n",
        "            nome = token.head.lemma_\n",
        "            adj = token.lemma_\n",
        "            return {\"frase_limpa\": frase, \"nome\": nome, \"adjetivo\": adj}\n",
        "    return None\n",
        "\n",
        "def extrair_adj_n(frase):\n",
        "    doc = nlp(frase)\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"ADJ\" and token.head.pos_ == \"NOUN\" and token.i < token.head.i:\n",
        "            return {\"frase_limpa\": frase, \"adjetivo\": token.lemma_, \"nome\": token.head.lemma_}\n",
        "    for i in range(len(doc) - 1):\n",
        "        if doc[i].pos_ == \"ADJ\" and doc[i + 1].pos_ == \"NOUN\":\n",
        "            return {\"frase_limpa\": frase, \"adjetivo\": doc[i].lemma_, \"nome\": doc[i + 1].lemma_}\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "98ionmDo5urk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Domínios WordNet + Mapeamento\n",
        "# ===============================\n",
        "mapeamento_dominios = {\n",
        "    'noun.person': 'pessoa',\n",
        "    'noun.artifact': 'objeto',\n",
        "    'noun.act': 'evento',\n",
        "    'noun.event': 'evento',\n",
        "    'noun.group': 'organização',\n",
        "    'noun.location': 'lugar',\n",
        "    'noun.communication': 'comunicação',\n",
        "    'noun.state': 'estado',\n",
        "    'noun.cognition': 'conhecimento',\n",
        "    'noun.quantity': 'quantidade',\n",
        "    'noun.attribute': 'característica',\n",
        "    'noun.time': 'tempo',\n",
        "    'noun.animal': 'animal',\n",
        "    'noun.body': 'corpo',\n",
        "    'noun.food': 'comida',\n",
        "    'noun.substance': 'matéria',\n",
        "    'noun.object': 'objeto',\n",
        "    'noun.feeling': 'emoção',\n",
        "    'noun.phenomenon': 'fenómeno',\n",
        "}\n",
        "\n",
        "def obter_dominios(word, lang='por'):\n",
        "    synsets = wn.synsets(word, lang=lang)\n",
        "    if not synsets:\n",
        "        return \"desconhecido\", \"desconhecido\"\n",
        "    primeiro = synsets[0]\n",
        "    subdominio = primeiro.lexname()\n",
        "    dominio_mapeado = mapeamento_dominios.get(subdominio, \"outro\")\n",
        "    return dominio_mapeado, subdominio\n"
      ],
      "metadata": {
        "id": "xPiNTA0F5upc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Processamento das frases e domínios\n",
        "# ========================================\n",
        "dados = []\n",
        "for frase_limpa, frase_original in kwic_pairs:\n",
        "    if tipo_construcao == \"svo\":\n",
        "        extraido = extrair_svo(frase_limpa)\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        extraido = extrair_n_adj(frase_limpa)\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        extraido = extrair_adj_n(frase_limpa)\n",
        "    else:\n",
        "        extraido = None\n",
        "    if extraido:\n",
        "        extraido[\"frase_original\"] = frase_original\n",
        "        extraido[\"frase_limpa\"] = frase_limpa\n",
        "        dados.append(extraido)\n",
        "\n",
        "print(f\"Número de frases extraídas: {len(dados)}\")\n",
        "\n",
        "for entrada in dados:\n",
        "    if tipo_construcao == \"svo\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"objeto\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['verbo']} X\"\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"nome\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['nome']} + {entrada['adjetivo']}\"\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"nome\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['adjetivo']} {entrada['nome']}\"\n",
        "\n",
        "df = pd.DataFrame(dados)\n",
        "\n",
        "# ✅ NORMALIZAÇÃO\n",
        "if tipo_construcao in [\"n_adj\", \"adj_n\"]:\n",
        "    df[\"nome\"] = df[\"nome\"].str.lower()\n",
        "    df[\"adjetivo\"] = df[\"adjetivo\"].str.lower()\n",
        "\n",
        "if tipo_construcao == \"svo\":\n",
        "    verbos_leves = {\"fazer\", \"ter\", \"dar\", \"estar\", \"haver\", \"ficar\", \"pôr\", \"levar\", \"deixar\", \"manter\"}\n",
        "    df = df[~df[\"verbo\"].isin(verbos_leves)].copy()\n"
      ],
      "metadata": {
        "id": "v8-BoRdA5ukN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Análise de variabilidade semântica\n",
        "# ==========================================\n",
        "if tipo_construcao == \"svo\":\n",
        "    # Variabilidade verbo → objeto\n",
        "    agrupados_verbo_obj = df.groupby(\"verbo\")[\"dominio\"].apply(list)\n",
        "    df_var_verbo_obj = agrupados_verbo_obj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_verbo_obj\": len(set(x)),\n",
        "        \"dominios_obj\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "    # Variabilidade verbo → sujeito\n",
        "    df['dominio_sujeito'], df['subdominio_sujeito'] = zip(*df['sujeito'].apply(obter_dominios) if \"sujeito\" in df else [(\"desconhecido\", \"desconhecido\")] * len(df))\n",
        "    agrupados_verbo_suj = df.groupby(\"verbo\")[\"dominio_sujeito\"].apply(list)\n",
        "    df_var_verbo_suj = agrupados_verbo_suj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_verbo_suj\": len(set(x)),\n",
        "        \"dominios_suj\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "\n",
        "elif tipo_construcao == \"adj_n\":\n",
        "    agrupados = df.groupby(\"adjetivo\")[\"dominio\"].apply(list)\n",
        "    df_var = agrupados.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_semântica\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "    df_var = df_var.rename(columns={\"adjetivo\": \"construcao\"})\n",
        "\n",
        "elif tipo_construcao == \"n_adj\":\n",
        "    df['dominio_adjetivo'], df['subdominio_adjetivo'] = zip(*df['adjetivo'].apply(obter_dominios))\n",
        "\n",
        "    agrupados_nome = df.groupby(\"nome\")[\"dominio_adjetivo\"].apply(list)\n",
        "    df_var_nome = agrupados_nome.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_nome\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "    agrupados_adj = df.groupby(\"adjetivo\")[\"dominio\"].apply(list)\n",
        "    df_var_adj = agrupados_adj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_adjetivo\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ig5Rg4od5uhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Exibir exemplos e estatísticas\n",
        "# ===============================\n",
        "print(f\"\\n📊 Top 10 construções ({tipo_construcao}):\")\n",
        "\n",
        "if tipo_construcao == \"n_adj\":\n",
        "    df_var_nome_sorted = df_var_nome.sort_values(by=\"variabilidade_nome\", ascending=False)\n",
        "    df_var_adj_sorted = df_var_adj.sort_values(by=\"variabilidade_adjetivo\", ascending=False)\n",
        "\n",
        "    print(\"\\n🔸 Variabilidade por **nome**:\")\n",
        "    print(df_var_nome_sorted.head(10))\n",
        "\n",
        "    print(\"\\n🔸 Variabilidade por **adjetivo**:\")\n",
        "    print(df_var_adj_sorted.head(10))\n",
        "\n",
        "    print(f\"\\n📌 Exemplos para os 5 nomes mais variáveis:\")\n",
        "    for nome in df_var_nome_sorted.head(5)[\"nome\"]:\n",
        "        print(f\"\\n🔹 Nome: {nome.capitalize()}\")\n",
        "        frases_filtradas = df[df[\"nome\"] == nome].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Adjetivo: {row['adjetivo']} | Domínio: {row['dominio_adjetivo']} | Subdomínio: {row['subdominio_adjetivo']}\")\n",
        "\n",
        "    print(f\"\\n📌 Exemplos para os 5 adjetivos mais variáveis:\")\n",
        "    for adj in df_var_adj_sorted.head(5)[\"adjetivo\"]:\n",
        "        print(f\"\\n🔹 Adjetivo: {adj}\")\n",
        "        frases_filtradas = df[df[\"adjetivo\"] == adj].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Nome: {row['nome']} | Domínio: {row['dominio']} | Subdomínio: {row['subdominio']}\")\n",
        "\n",
        "elif tipo_construcao == \"svo\":\n",
        "    df_var_obj_sorted = df_var_verbo_obj.sort_values(by=\"variabilidade_verbo_obj\", ascending=False)\n",
        "    df_var_suj_sorted = df_var_verbo_suj.sort_values(by=\"variabilidade_verbo_suj\", ascending=False)\n",
        "\n",
        "    print(\"\\n🔸 Variabilidade verbo → objeto:\")\n",
        "    print(df_var_obj_sorted.head(10))\n",
        "\n",
        "    print(\"\\n🔸 Variabilidade verbo → sujeito:\")\n",
        "    print(df_var_suj_sorted.head(10))\n",
        "\n",
        "    print(f\"\\n📌 Exemplos para os 5 verbos mais variáveis (objeto):\")\n",
        "    for verbo in df_var_obj_sorted.head(5)[\"verbo\"]:\n",
        "        print(f\"\\n🔹 Verbo: {verbo}\")\n",
        "        frases_filtradas = df[df[\"verbo\"] == verbo].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Objeto: {row['objeto']} | Domínio_obj: {row['dominio']} | Subdomínio_obj: {row['subdominio']}\")\n",
        "\n",
        "    print(f\"\\n📌 Exemplos para os 5 verbos mais variáveis (sujeito):\")\n",
        "    for verbo in df_var_suj_sorted.head(5)[\"verbo\"]:\n",
        "        print(f\"\\n🔹 Verbo: {verbo}\")\n",
        "        frases_filtradas = df[df[\"verbo\"] == verbo].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Sujeito: {row['sujeito']} | Domínio_suj: {row['dominio_sujeito']} | Subdomínio_suj: {row['subdominio_sujeito']}\")\n",
        "\n",
        "\n",
        "elif tipo_construcao == \"adj_n\":\n",
        "    df_var_sorted = df_var.sort_values(by=\"variabilidade_semântica\", ascending=False)\n",
        "\n",
        "    print(df_var_sorted.head(10))\n",
        "    print(f\"\\n📌 Exemplos para os 5 adjetivos mais variáveis:\")\n",
        "    for adj in df_var_sorted.head(5)[\"construcao\"].str.split().str[0]:\n",
        "        print(f\"\\n🔹 Adjetivo: {adj}\")\n",
        "        frases_filtradas = df[df[\"adjetivo\"] == adj].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Nome: {row['nome']} | Domínio: {row['dominio']} | Subdomínio: {row['subdominio']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LqoDkAj35uYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Estatísticas gerais\n",
        "# ===============================\n",
        "total = len(df)\n",
        "desconhecidos = df[df['dominio'] == \"desconhecido\"].shape[0]\n",
        "percentagem = 100 * (total - desconhecidos) / total if total else 0\n",
        "print(f\"\\n📊 Percentagem de Domínios Atribuídos:\")\n",
        "print(f\" - Atribuídos: {percentagem:.2f}%\")\n",
        "print(f\" - 'Desconhecido': {100 - percentagem:.2f}%\")"
      ],
      "metadata": {
        "id": "cZpzOG-A6GoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "M7WMAn1m1hmI"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Exportar para Excel na Drive\n",
        "# ===============================\n",
        "\n",
        "# Criar nome do ficheiro com tipo da construção e data/hora\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_path = f\"/content/drive/MyDrive/Constructions_concordances/output_variabilidade_{tipo_construcao}_{timestamp}.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "    df.to_excel(writer, index=False, sheet_name=\"Construcoes\")\n",
        "\n",
        "    if tipo_construcao == \"svo\":\n",
        "        df_var_obj_sorted = df_var_verbo_obj.sort_values(by=\"variabilidade_verbo_obj\", ascending=False)\n",
        "        df_var_suj_sorted = df_var_verbo_suj.sort_values(by=\"variabilidade_verbo_suj\", ascending=False)\n",
        "        df_var_obj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_verbo_objeto\")\n",
        "        df_var_suj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_verbo_sujeito\")\n",
        "\n",
        "\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        df_var_nome_sorted = df_var_nome.sort_values(by=\"variabilidade_nome\", ascending=False)\n",
        "        df_var_adj_sorted = df_var_adj.sort_values(by=\"variabilidade_adjetivo\", ascending=False)\n",
        "\n",
        "        df_var_nome_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_nome\")\n",
        "        df_var_adj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_adjetivo\")\n",
        "\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        df_var_sorted = df_var.sort_values(by=\"variabilidade_semântica\", ascending=False)\n",
        "        df_var_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade\")\n",
        "\n",
        "print(f\"\\n📁 Ficheiro exportado com sucesso: {output_path}\")\n",
        "\n"
      ]
    }
  ]
}