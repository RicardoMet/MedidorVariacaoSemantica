{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# DependÃªncias e setup\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from datetime import datetime\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "!pip install -q spacy openpyxl\n",
        "!python -m spacy download pt_core_news_lg\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_lg\")"
      ],
      "metadata": {
        "id": "a7FRY46b5t9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Montar Google Drive\n",
        "# ======================\n",
        "drive.mount('/content/drive/')\n",
        "file = \"/content/drive/MyDrive/Constructions_concordances/EXEMPLO.xml\" #<------ Substituir nome do ficheiro pelo do ficheiro a analisar"
      ],
      "metadata": {
        "id": "IsGkHD_w5u3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# Escolher a construÃ§Ã£o\n",
        "# ======================\n",
        "tipo_construcao = \"svo\"  # 'svo', 'n_adj', 'adj_n'"
      ],
      "metadata": {
        "id": "AD-xXWIC5u1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# FunÃ§Ãµes de prÃ©-processamento\n",
        "# =============================\n",
        "def limpar_kwic(texto_kwic):\n",
        "    return re.sub(r\"/[a-z]+\", \"\", texto_kwic)\n",
        "\n",
        "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "    xml = f.read()\n",
        "\n",
        "soup = BeautifulSoup(xml, \"xml\")\n",
        "kwics = soup.find_all(\"kwic\")\n",
        "kwic_pairs = [(limpar_kwic(k.text.strip()), k.text.strip()) for k in kwics]\n",
        "\n",
        "frases_limpas = [pair[0] for pair in kwic_pairs]\n",
        "frases_originais = [pair[1] for pair in kwic_pairs]"
      ],
      "metadata": {
        "id": "oNRCi0lJ5uuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================================\n",
        "# FunÃ§Ãµes de extraÃ§Ã£o sintÃ¡tica\n",
        "# ===================================\n",
        "def extrair_svo(frase):\n",
        "    doc = nlp(frase)\n",
        "    sujeito = verbo = objeto = None\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            verbo = token.lemma_\n",
        "        elif token.dep_ == \"nsubj\":\n",
        "            sujeito = token.text\n",
        "        elif token.dep_ in {\"obj\", \"dobj\", \"obl\", \"attr\"}:\n",
        "            objeto = token.lemma_\n",
        "    if verbo and (sujeito or objeto):\n",
        "        return {\n",
        "            \"frase_limpa\": frase,\n",
        "            \"sujeito\": sujeito if sujeito else \"\",\n",
        "            \"verbo\": verbo,\n",
        "            \"objeto\": objeto if objeto else \"\"\n",
        "        }\n",
        "    return None\n",
        "\n",
        "def extrair_n_adj(frase):\n",
        "    doc = nlp(frase)\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"ADJ\" and token.head.pos_ == \"NOUN\":\n",
        "            nome = token.head.lemma_\n",
        "            adj = token.lemma_\n",
        "            return {\"frase_limpa\": frase, \"nome\": nome, \"adjetivo\": adj}\n",
        "    return None\n",
        "\n",
        "def extrair_adj_n(frase):\n",
        "    doc = nlp(frase)\n",
        "    for token in doc:\n",
        "        if token.pos_ == \"ADJ\" and token.head.pos_ == \"NOUN\" and token.i < token.head.i:\n",
        "            return {\"frase_limpa\": frase, \"adjetivo\": token.lemma_, \"nome\": token.head.lemma_}\n",
        "    for i in range(len(doc) - 1):\n",
        "        if doc[i].pos_ == \"ADJ\" and doc[i + 1].pos_ == \"NOUN\":\n",
        "            return {\"frase_limpa\": frase, \"adjetivo\": doc[i].lemma_, \"nome\": doc[i + 1].lemma_}\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "98ionmDo5urk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# DomÃ­nios WordNet + Mapeamento\n",
        "# ===============================\n",
        "mapeamento_dominios = {\n",
        "    'noun.person': 'pessoa',\n",
        "    'noun.artifact': 'objeto',\n",
        "    'noun.act': 'evento',\n",
        "    'noun.event': 'evento',\n",
        "    'noun.group': 'organizaÃ§Ã£o',\n",
        "    'noun.location': 'lugar',\n",
        "    'noun.communication': 'comunicaÃ§Ã£o',\n",
        "    'noun.state': 'estado',\n",
        "    'noun.cognition': 'conhecimento',\n",
        "    'noun.quantity': 'quantidade',\n",
        "    'noun.attribute': 'caracterÃ­stica',\n",
        "    'noun.time': 'tempo',\n",
        "    'noun.animal': 'animal',\n",
        "    'noun.body': 'corpo',\n",
        "    'noun.food': 'comida',\n",
        "    'noun.substance': 'matÃ©ria',\n",
        "    'noun.object': 'objeto',\n",
        "    'noun.feeling': 'emoÃ§Ã£o',\n",
        "    'noun.phenomenon': 'fenÃ³meno',\n",
        "}\n",
        "\n",
        "def obter_dominios(word, lang='por'):\n",
        "    synsets = wn.synsets(word, lang=lang)\n",
        "    if not synsets:\n",
        "        return \"desconhecido\", \"desconhecido\"\n",
        "    primeiro = synsets[0]\n",
        "    subdominio = primeiro.lexname()\n",
        "    dominio_mapeado = mapeamento_dominios.get(subdominio, \"outro\")\n",
        "    return dominio_mapeado, subdominio\n"
      ],
      "metadata": {
        "id": "xPiNTA0F5upc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# Processamento das frases e domÃ­nios\n",
        "# ========================================\n",
        "dados = []\n",
        "for frase_limpa, frase_original in kwic_pairs:\n",
        "    if tipo_construcao == \"svo\":\n",
        "        extraido = extrair_svo(frase_limpa)\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        extraido = extrair_n_adj(frase_limpa)\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        extraido = extrair_adj_n(frase_limpa)\n",
        "    else:\n",
        "        extraido = None\n",
        "    if extraido:\n",
        "        extraido[\"frase_original\"] = frase_original\n",
        "        extraido[\"frase_limpa\"] = frase_limpa\n",
        "        dados.append(extraido)\n",
        "\n",
        "print(f\"NÃºmero de frases extraÃ­das: {len(dados)}\")\n",
        "\n",
        "for entrada in dados:\n",
        "    if tipo_construcao == \"svo\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"objeto\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['verbo']} X\"\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"nome\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['nome']} + {entrada['adjetivo']}\"\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        entrada[\"dominio\"], entrada[\"subdominio\"] = obter_dominios(entrada[\"nome\"])\n",
        "        entrada[\"construcao\"] = f\"{entrada['adjetivo']} {entrada['nome']}\"\n",
        "\n",
        "df = pd.DataFrame(dados)\n",
        "\n",
        "# âœ… NORMALIZAÃ‡ÃƒO\n",
        "if tipo_construcao in [\"n_adj\", \"adj_n\"]:\n",
        "    df[\"nome\"] = df[\"nome\"].str.lower()\n",
        "    df[\"adjetivo\"] = df[\"adjetivo\"].str.lower()\n",
        "\n",
        "if tipo_construcao == \"svo\":\n",
        "    verbos_leves = {\"fazer\", \"ter\", \"dar\", \"estar\", \"haver\", \"ficar\", \"pÃ´r\", \"levar\", \"deixar\", \"manter\"}\n",
        "    df = df[~df[\"verbo\"].isin(verbos_leves)].copy()\n"
      ],
      "metadata": {
        "id": "v8-BoRdA5ukN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# AnÃ¡lise de variabilidade semÃ¢ntica\n",
        "# ==========================================\n",
        "if tipo_construcao == \"svo\":\n",
        "    # Variabilidade verbo â†’ objeto\n",
        "    agrupados_verbo_obj = df.groupby(\"verbo\")[\"dominio\"].apply(list)\n",
        "    df_var_verbo_obj = agrupados_verbo_obj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_verbo_obj\": len(set(x)),\n",
        "        \"dominios_obj\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "    # Variabilidade verbo â†’ sujeito\n",
        "    df['dominio_sujeito'], df['subdominio_sujeito'] = zip(*df['sujeito'].apply(obter_dominios) if \"sujeito\" in df else [(\"desconhecido\", \"desconhecido\")] * len(df))\n",
        "    agrupados_verbo_suj = df.groupby(\"verbo\")[\"dominio_sujeito\"].apply(list)\n",
        "    df_var_verbo_suj = agrupados_verbo_suj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_verbo_suj\": len(set(x)),\n",
        "        \"dominios_suj\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "\n",
        "elif tipo_construcao == \"adj_n\":\n",
        "    agrupados = df.groupby(\"adjetivo\")[\"dominio\"].apply(list)\n",
        "    df_var = agrupados.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_semÃ¢ntica\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "    df_var = df_var.rename(columns={\"adjetivo\": \"construcao\"})\n",
        "\n",
        "elif tipo_construcao == \"n_adj\":\n",
        "    df['dominio_adjetivo'], df['subdominio_adjetivo'] = zip(*df['adjetivo'].apply(obter_dominios))\n",
        "\n",
        "    agrupados_nome = df.groupby(\"nome\")[\"dominio_adjetivo\"].apply(list)\n",
        "    df_var_nome = agrupados_nome.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_nome\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n",
        "    agrupados_adj = df.groupby(\"adjetivo\")[\"dominio\"].apply(list)\n",
        "    df_var_adj = agrupados_adj.apply(lambda x: pd.Series({\n",
        "        \"variabilidade_adjetivo\": len(set(x)),\n",
        "        \"dominios\": \", \".join(sorted(set(x)))\n",
        "    })).reset_index()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ig5Rg4od5uhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Exibir exemplos e estatÃ­sticas\n",
        "# ===============================\n",
        "print(f\"\\nðŸ“Š Top 10 construÃ§Ãµes ({tipo_construcao}):\")\n",
        "\n",
        "if tipo_construcao == \"n_adj\":\n",
        "    df_var_nome_sorted = df_var_nome.sort_values(by=\"variabilidade_nome\", ascending=False)\n",
        "    df_var_adj_sorted = df_var_adj.sort_values(by=\"variabilidade_adjetivo\", ascending=False)\n",
        "\n",
        "    print(\"\\nðŸ”¸ Variabilidade por **nome**:\")\n",
        "    print(df_var_nome_sorted.head(10))\n",
        "\n",
        "    print(\"\\nðŸ”¸ Variabilidade por **adjetivo**:\")\n",
        "    print(df_var_adj_sorted.head(10))\n",
        "\n",
        "    print(f\"\\nðŸ“Œ Exemplos para os 5 nomes mais variÃ¡veis:\")\n",
        "    for nome in df_var_nome_sorted.head(5)[\"nome\"]:\n",
        "        print(f\"\\nðŸ”¹ Nome: {nome.capitalize()}\")\n",
        "        frases_filtradas = df[df[\"nome\"] == nome].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Adjetivo: {row['adjetivo']} | DomÃ­nio: {row['dominio_adjetivo']} | SubdomÃ­nio: {row['subdominio_adjetivo']}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Œ Exemplos para os 5 adjetivos mais variÃ¡veis:\")\n",
        "    for adj in df_var_adj_sorted.head(5)[\"adjetivo\"]:\n",
        "        print(f\"\\nðŸ”¹ Adjetivo: {adj}\")\n",
        "        frases_filtradas = df[df[\"adjetivo\"] == adj].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Nome: {row['nome']} | DomÃ­nio: {row['dominio']} | SubdomÃ­nio: {row['subdominio']}\")\n",
        "\n",
        "elif tipo_construcao == \"svo\":\n",
        "    df_var_obj_sorted = df_var_verbo_obj.sort_values(by=\"variabilidade_verbo_obj\", ascending=False)\n",
        "    df_var_suj_sorted = df_var_verbo_suj.sort_values(by=\"variabilidade_verbo_suj\", ascending=False)\n",
        "\n",
        "    print(\"\\nðŸ”¸ Variabilidade verbo â†’ objeto:\")\n",
        "    print(df_var_obj_sorted.head(10))\n",
        "\n",
        "    print(\"\\nðŸ”¸ Variabilidade verbo â†’ sujeito:\")\n",
        "    print(df_var_suj_sorted.head(10))\n",
        "\n",
        "    print(f\"\\nðŸ“Œ Exemplos para os 5 verbos mais variÃ¡veis (objeto):\")\n",
        "    for verbo in df_var_obj_sorted.head(5)[\"verbo\"]:\n",
        "        print(f\"\\nðŸ”¹ Verbo: {verbo}\")\n",
        "        frases_filtradas = df[df[\"verbo\"] == verbo].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Objeto: {row['objeto']} | DomÃ­nio_obj: {row['dominio']} | SubdomÃ­nio_obj: {row['subdominio']}\")\n",
        "\n",
        "    print(f\"\\nðŸ“Œ Exemplos para os 5 verbos mais variÃ¡veis (sujeito):\")\n",
        "    for verbo in df_var_suj_sorted.head(5)[\"verbo\"]:\n",
        "        print(f\"\\nðŸ”¹ Verbo: {verbo}\")\n",
        "        frases_filtradas = df[df[\"verbo\"] == verbo].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Sujeito: {row['sujeito']} | DomÃ­nio_suj: {row['dominio_sujeito']} | SubdomÃ­nio_suj: {row['subdominio_sujeito']}\")\n",
        "\n",
        "\n",
        "elif tipo_construcao == \"adj_n\":\n",
        "    df_var_sorted = df_var.sort_values(by=\"variabilidade_semÃ¢ntica\", ascending=False)\n",
        "\n",
        "    print(df_var_sorted.head(10))\n",
        "    print(f\"\\nðŸ“Œ Exemplos para os 5 adjetivos mais variÃ¡veis:\")\n",
        "    for adj in df_var_sorted.head(5)[\"construcao\"].str.split().str[0]:\n",
        "        print(f\"\\nðŸ”¹ Adjetivo: {adj}\")\n",
        "        frases_filtradas = df[df[\"adjetivo\"] == adj].head(4)\n",
        "        for _, row in frases_filtradas.iterrows():\n",
        "            print(f\" - Frase: {row['frase_limpa']} | Nome: {row['nome']} | DomÃ­nio: {row['dominio']} | SubdomÃ­nio: {row['subdominio']}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LqoDkAj35uYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# EstatÃ­sticas gerais\n",
        "# ===============================\n",
        "total = len(df)\n",
        "desconhecidos = df[df['dominio'] == \"desconhecido\"].shape[0]\n",
        "percentagem = 100 * (total - desconhecidos) / total if total else 0\n",
        "print(f\"\\nðŸ“Š Percentagem de DomÃ­nios AtribuÃ­dos:\")\n",
        "print(f\" - AtribuÃ­dos: {percentagem:.2f}%\")\n",
        "print(f\" - 'Desconhecido': {100 - percentagem:.2f}%\")"
      ],
      "metadata": {
        "id": "cZpzOG-A6GoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "M7WMAn1m1hmI"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Exportar para Excel na Drive\n",
        "# ===============================\n",
        "\n",
        "# Criar nome do ficheiro com tipo da construÃ§Ã£o e data/hora\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_path = f\"/content/drive/MyDrive/Constructions_concordances/output_variabilidade_{tipo_construcao}_{timestamp}.xlsx\"\n",
        "\n",
        "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "    df.to_excel(writer, index=False, sheet_name=\"Construcoes\")\n",
        "\n",
        "    if tipo_construcao == \"svo\":\n",
        "        df_var_obj_sorted = df_var_verbo_obj.sort_values(by=\"variabilidade_verbo_obj\", ascending=False)\n",
        "        df_var_suj_sorted = df_var_verbo_suj.sort_values(by=\"variabilidade_verbo_suj\", ascending=False)\n",
        "        df_var_obj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_verbo_objeto\")\n",
        "        df_var_suj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_verbo_sujeito\")\n",
        "\n",
        "\n",
        "    elif tipo_construcao == \"n_adj\":\n",
        "        df_var_nome_sorted = df_var_nome.sort_values(by=\"variabilidade_nome\", ascending=False)\n",
        "        df_var_adj_sorted = df_var_adj.sort_values(by=\"variabilidade_adjetivo\", ascending=False)\n",
        "\n",
        "        df_var_nome_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_nome\")\n",
        "        df_var_adj_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade_adjetivo\")\n",
        "\n",
        "    elif tipo_construcao == \"adj_n\":\n",
        "        df_var_sorted = df_var.sort_values(by=\"variabilidade_semÃ¢ntica\", ascending=False)\n",
        "        df_var_sorted.to_excel(writer, index=False, sheet_name=\"Variabilidade\")\n",
        "\n",
        "print(f\"\\nðŸ“ Ficheiro exportado com sucesso: {output_path}\")\n",
        "\n"
      ]
    }
  ]
}