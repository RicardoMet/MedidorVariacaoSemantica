"""
AnÃ¡lise de Variabilidade SemÃ¢ntica em ConstruÃ§Ãµes SintÃ¡ticas (PortuguÃªs)

Autor: [O Teu Nome]
DescriÃ§Ã£o:
-----------
Este script processa ficheiros XML contendo resultados de KWIC (Key Word in Context)
extraÃ­dos de corpora atravÃ©s de expressÃµes regulares.

Suporta trÃªs tipos de construÃ§Ãµes:
- 'svo'   â†’ Sujeito + Verbo + Objeto
- 'n_adj' â†’ Nome + Adjetivo
- 'adj_n' â†’ Adjetivo + Nome

Funcionalidades:
----------------
1. Extrai construÃ§Ãµes sintÃ¡ticas via spaCy.
2. Atribui domÃ­nios semÃ¢nticos a nomes, verbos e adjetivos via WordNet.
3. Calcula variabilidade semÃ¢ntica de cada elemento:
   - Para SVO: verbo em relaÃ§Ã£o a objetos **e** sujeitos.
   - Para n_adj: nome e adjetivo.
   - Para adj_n: adjetivo.
4. Exporta resultados para Excel com vÃ¡rias folhas:
   - ConstruÃ§Ãµes extraÃ­das
   - Tabelas de variabilidade
5. Imprime estatÃ­sticas no terminal.

Input:
------
- Ficheiro XML com KWICs (resultados de pesquisa por expressÃ£o regular).

Output:
-------
- Excel com os resultados da anÃ¡lise.

"""

# =========================
# ğŸ”§ DependÃªncias e setup
# =========================
import pandas as pd
from bs4 import BeautifulSoup
import re
import spacy
import nltk
from nltk.corpus import wordnet as wn
from datetime import datetime

# Downloads necessÃ¡rios (apenas na 1Âª execuÃ§Ã£o)
nltk.download('wordnet')
nltk.download('omw-1.4')
import subprocess
subprocess.run(["python", "-m", "spacy", "download", "pt_core_news_lg"])

nlp = spacy.load("pt_core_news_lg")

# ======================
# ğŸ“ Input
# ======================
file = "input.xml"          # <- caminho do ficheiro XML
tipo_construcao = "svo"     # 'svo', 'n_adj', 'adj_n'

# =============================
# ğŸ§¹ PrÃ©-processamento
# =============================
def limpar_kwic(texto_kwic):
    return re.sub(r"/[a-z]+", "", texto_kwic)

with open(file, "r", encoding="utf-8") as f:
    xml = f.read()

soup = BeautifulSoup(xml, "xml")
kwics = soup.find_all("kwic")
kwic_pairs = [(limpar_kwic(k.text.strip()), k.text.strip()) for k in kwics]

# ===================================
# ğŸ“ ExtraÃ§Ã£o sintÃ¡tica
# ===================================
def extrair_svo(frase):
    doc = nlp(frase)
    sujeito = verbo = objeto = None
    for token in doc:
        if token.dep_ == "ROOT" and token.pos_ == "VERB":
            verbo = token.lemma_
        elif token.dep_ == "nsubj":
            sujeito = token.text
        elif token.dep_ in {"obj", "dobj", "obl", "attr"}:
            objeto = token.lemma_
    if verbo and (sujeito or objeto):
        return {
            "frase_limpa": frase,
            "sujeito": sujeito if sujeito else "",
            "verbo": verbo,
            "objeto": objeto if objeto else ""
        }
    return None

def extrair_n_adj(frase):
    doc = nlp(frase)
    for token in doc:
        if token.pos_ == "ADJ" and token.head.pos_ == "NOUN":
            return {"frase_limpa": frase, "nome": token.head.lemma_, "adjetivo": token.lemma_}
    return None

def extrair_adj_n(frase):
    doc = nlp(frase)
    for token in doc:
        if token.pos_ == "ADJ" and token.head.pos_ == "NOUN" and token.i < token.head.i:
            return {"frase_limpa": frase, "adjetivo": token.lemma_, "nome": token.head.lemma_}
    for i in range(len(doc) - 1):
        if doc[i].pos_ == "ADJ" and doc[i + 1].pos_ == "NOUN":
            return {"frase_limpa": frase, "adjetivo": doc[i].lemma_, "nome": doc[i + 1].lemma_}
    return None

# ===============================
# ğŸ§  DomÃ­nios WordNet
# ===============================
mapeamento_dominios = {
    'noun.person': 'pessoa',
    'noun.artifact': 'objeto',
    'noun.act': 'evento',
    'noun.event': 'evento',
    'noun.group': 'organizaÃ§Ã£o',
    'noun.location': 'lugar',
    'noun.communication': 'comunicaÃ§Ã£o',
    'noun.state': 'estado',
    'noun.cognition': 'conhecimento',
    'noun.quantity': 'quantidade',
    'noun.attribute': 'caracterÃ­stica',
    'noun.time': 'tempo',
    'noun.animal': 'animal',
    'noun.body': 'corpo',
    'noun.food': 'comida',
    'noun.substance': 'matÃ©ria',
    'noun.object': 'objeto',
    'noun.feeling': 'emoÃ§Ã£o',
    'noun.phenomenon': 'fenÃ´meno',
}

def obter_dominios(word, lang='por'):
    if not word:
        return "desconhecido", "desconhecido"
    synsets = wn.synsets(word, lang=lang)
    if not synsets:
        return "desconhecido", "desconhecido"
    primeiro = synsets[0]
    subdominio = primeiro.lexname()
    dominio_mapeado = mapeamento_dominios.get(subdominio, "outro")
    return dominio_mapeado, subdominio

# ========================================
# ğŸ”„ Processamento das frases
# ========================================
dados = []
for frase_limpa, frase_original in kwic_pairs:
    if tipo_construcao == "svo":
        extraido = extrair_svo(frase_limpa)
    elif tipo_construcao == "n_adj":
        extraido = extrair_n_adj(frase_limpa)
    elif tipo_construcao == "adj_n":
        extraido = extrair_adj_n(frase_limpa)
    else:
        extraido = None
    if extraido:
        extraido["frase_original"] = frase_original
        extraido["frase_limpa"] = frase_limpa
        dados.append(extraido)

print(f"NÃºmero de frases extraÃ­das: {len(dados)}")

for entrada in dados:
    if tipo_construcao == "svo":
        entrada["dominio"], entrada["subdominio"] = obter_dominios(entrada["objeto"])
        entrada["dominio_sujeito"], entrada["subdominio_sujeito"] = obter_dominios(entrada["sujeito"])
        entrada["construcao"] = f"{entrada['verbo']} X"
    elif tipo_construcao == "n_adj":
        entrada["dominio"], entrada["subdominio"] = obter_dominios(entrada["nome"])
        entrada["construcao"] = f"{entrada['nome']} + {entrada['adjetivo']}"
    elif tipo_construcao == "adj_n":
        entrada["dominio"], entrada["subdominio"] = obter_dominios(entrada["nome"])
        entrada["construcao"] = f"{entrada['adjetivo']} {entrada['nome']}"

df = pd.DataFrame(dados)

# ========================================
# ğŸ“Š Variabilidade semÃ¢ntica
# ========================================
if tipo_construcao == "svo":
    # verbo â†’ objeto
    agrupados_verbo_obj = df.groupby("verbo")["dominio"].apply(list)
    df_var_verbo_obj = agrupados_verbo_obj.apply(lambda x: pd.Series({
        "variabilidade_verbo_obj": len(set(x)),
        "dominios_obj": ", ".join(sorted(set(x)))
    })).reset_index()

    # verbo â†’ sujeito
    agrupados_verbo_suj = df.groupby("verbo")["dominio_sujeito"].apply(list)
    df_var_verbo_suj = agrupados_verbo_suj.apply(lambda x: pd.Series({
        "variabilidade_verbo_suj": len(set(x)),
        "dominios_suj": ", ".join(sorted(set(x)))
    })).reset_index()

elif tipo_construcao == "adj_n":
    agrupados = df.groupby("adjetivo")["dominio"].apply(list)
    df_var = agrupados.apply(lambda x: pd.Series({
        "variabilidade_semÃ¢ntica": len(set(x)),
        "dominios": ", ".join(sorted(set(x)))
    })).reset_index()

elif tipo_construcao == "n_adj":
    df['dominio_adjetivo'], df['subdominio_adjetivo'] = zip(*df['adjetivo'].apply(obter_dominios))
    agrupados_nome = df.groupby("nome")["dominio_adjetivo"].apply(list)
    df_var_nome = agrupados_nome.apply(lambda x: pd.Series({
        "variabilidade_nome": len(set(x)),
        "dominios": ", ".join(sorted(set(x)))
    })).reset_index()
    agrupados_adj = df.groupby("adjetivo")["dominio"].apply(list)
    df_var_adj = agrupados_adj.apply(lambda x: pd.Series({
        "variabilidade_adjetivo": len(set(x)),
        "dominios": ", ".join(sorted(set(x)))
    })).reset_index()

# ===============================
# ğŸ“¤ Exportar para Excel
# ===============================
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
output_path = f"output_variabilidade_{tipo_construcao}_{timestamp}.xlsx"

with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
    df.to_excel(writer, index=False, sheet_name="Construcoes")

    if tipo_construcao == "svo":
        df_var_obj_sorted = df_var_verbo_obj.sort_values(by="variabilidade_verbo_obj", ascending=False)
        df_var_suj_sorted = df_var_verbo_suj.sort_values(by="variabilidade_verbo_suj", ascending=False)
        df_var_obj_sorted.to_excel(writer, index=False, sheet_name="Variabilidade_verbo_objeto")
        df_var_suj_sorted.to_excel(writer, index=False, sheet_name="Variabilidade_verbo_sujeito")

    elif tipo_construcao == "n_adj":
        df_var_nome_sorted = df_var_nome.sort_values(by="variabilidade_nome", ascending=False)
        df_var_adj_sorted = df_var_adj.sort_values(by="variabilidade_adjetivo", ascending=False)
        df_var_nome_sorted.to_excel(writer, index=False, sheet_name="Variabilidade_nome")
        df_var_adj_sorted.to_excel(writer, index=False, sheet_name="Variabilidade_adjetivo")

    elif tipo_construcao == "adj_n":
        df_var_sorted = df_var.sort_values(by="variabilidade_semÃ¢ntica", ascending=False)
        df_var_sorted.to_excel(writer, index=False, sheet_name="Variabilidade")

print(f"ğŸ“ Ficheiro exportado com sucesso: {output_path}")
